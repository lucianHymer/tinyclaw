/**
 * Dashboard - Real-time monitoring server for Borg
 * Serves a single HTML page with 7 views and provides API + SSE endpoints.
 */

import express from "express";
import fs from "fs";
import path from "path";
import http from "http";
import {
    type DockerContainerInspect,
    fetchDockerJson,
    fetchDockerStats,
    getAllContainers,
    isValidContainerId,
    validateAndUpdateMemory,
    OS_RESERVE_BYTES,
} from "./docker-client.js";
import { parseMeminfo, parseCpuPercent, getDiskUsage, countQueueFiles, PROC_BASE } from "./host-metrics.js";
import { toErrorMessage, isValidSessionId, ValidationError } from "./types.js";

const SCRIPT_DIR = path.resolve(__dirname, "..");
const BORG_DIR = path.join(SCRIPT_DIR, ".borg");
const STATIC_DIR = path.join(SCRIPT_DIR, "static");
const SESSIONS_DIR = path.join(BORG_DIR, "sessions");
const PORT = parseInt(process.env.DASHBOARD_PORT || "3100", 10);
const DOCKER_PROXY_URL = process.env.DOCKER_PROXY_URL || "http://localhost:2375";
const COMPOSE_PROJECT = process.env.COMPOSE_PROJECT || "";
if (!COMPOSE_PROJECT) {
    console.warn("COMPOSE_PROJECT not set — infra containers will not be shown");
}

// ─── JSONL Readers ───

interface TailState {
    offset: number;
}

// Read the last N entries from a JSONL file (read from end)
function readRecentJsonl<T = unknown>(filePath: string, n: number): T[] {
    if (!fs.existsSync(filePath)) return [];
    const stat = fs.statSync(filePath);
    if (stat.size === 0) return [];

    const TAIL_BYTES = Math.min(256 * 1024, stat.size); // 256KB max
    const fd = fs.openSync(filePath, "r");
    try {
        const buf = Buffer.alloc(TAIL_BYTES);
        const readStart = Math.max(0, stat.size - TAIL_BYTES);
        fs.readSync(fd, buf, 0, TAIL_BYTES, readStart);
        const content = buf.toString("utf8");
        const lines = content.split("\n").filter(l => l.trim());
        // Skip first line if we started mid-file (likely truncated)
        if (readStart > 0 && lines.length > 0) lines.shift();

        const entries: T[] = [];
        for (const line of lines) {
            try {
                entries.push(JSON.parse(line) as T);
            } catch {
                /* skip malformed */
            }
        }
        return entries.slice(-n);
    } finally {
        fs.closeSync(fd);
    }
}

// ─── Host Metrics (dashboard-local) ───

function parseLoadAvg(): { load1: number; load5: number; load15: number } {
    try {
        const content = fs.readFileSync(path.join(PROC_BASE, "loadavg"), "utf8");
        const parts = content.split(/\s+/);
        return {
            load1: parseFloat(parts[0]),
            load5: parseFloat(parts[1]),
            load15: parseFloat(parts[2]),
        };
    } catch {
        return { load1: 0, load5: 0, load15: 0 };
    }
}

// ─── Helpers ───

function readJsonSafe<T>(filePath: string, fallback: T): T {
    try {
        return JSON.parse(fs.readFileSync(filePath, "utf8")) as T;
    } catch {
        return fallback;
    }
}

// ─── Per-client SSE tail reader ───
// Each SSE client gets its own offset tracking so multiple dashboard
// clients don't interfere with each other.

function readNewBytes(filePath: string, state: TailState): string | null {
    if (!fs.existsSync(filePath)) return null;
    const newStat = fs.statSync(filePath);
    // Detect rotation
    if (newStat.size < state.offset) state.offset = 0;
    // Nothing new
    if (newStat.size === state.offset) return null;

    const fd = fs.openSync(filePath, "r");
    try {
        const bytesToRead = newStat.size - state.offset;
        const buf = Buffer.alloc(bytesToRead);
        fs.readSync(fd, buf, 0, bytesToRead, state.offset);
        state.offset = newStat.size;
        return buf.toString("utf8");
    } finally {
        fs.closeSync(fd);
    }
}

// ─── Express App ───

const app = express();

// JSON body parser (needed for POST endpoints)
app.use(express.json());

// Serve static files
app.use("/static", express.static(STATIC_DIR));

// GET / — serves the dashboard HTML
app.get("/", (_req, res) => {
    const htmlPath = path.join(STATIC_DIR, "dashboard.html");
    if (fs.existsSync(htmlPath)) {
        res.sendFile(htmlPath);
    } else {
        res.status(404).send("Dashboard HTML not found. Place static/dashboard.html.");
    }
});

// GET /health
app.get("/health", (_req, res) => {
    res.json({ status: "ok", uptime: process.uptime() });
});

// GET /api/status — service health, queue depth, thread summary, host metrics
app.get("/api/status", (_req, res) => {
    const threads = readJsonSafe<Record<string, unknown>>(
        path.join(BORG_DIR, "threads.json"),
        {},
    );
    const queueIncoming = countQueueFiles(path.join(BORG_DIR, "queue/incoming"));
    const queueProcessing = countQueueFiles(path.join(BORG_DIR, "queue/processing"));
    const queueDeadLetter = countQueueFiles(path.join(BORG_DIR, "queue/dead-letter"));
    const memBytes = parseMeminfo();
    const cpu = parseCpuPercent();
    const load = parseLoadAvg();
    const disk = getDiskUsage(BORG_DIR);
    const mem = {
        totalMB: Math.round(memBytes.totalBytes / 1024 / 1024),
        usedMB: Math.round((memBytes.totalBytes - memBytes.availableBytes) / 1024 / 1024),
        availableMB: Math.round(memBytes.availableBytes / 1024 / 1024),
    };

    res.json({
        status: "ok",
        timestamp: Date.now(),
        queue: {
            incoming: queueIncoming,
            processing: queueProcessing,
            deadLetter: queueDeadLetter,
        },
        threads: Object.entries(threads).map(([id, cfg]) => ({
            id,
            ...(cfg as Record<string, unknown>),
        })),
        threadCount: Object.keys(threads).length,
        metrics: { cpu, mem, load, disk },
    });
});

// GET /api/threads — full threads.json
app.get("/api/threads", (_req, res) => {
    const threads = readJsonSafe(path.join(BORG_DIR, "threads.json"), {});
    res.json(threads);
});

// GET /api/threads/:id/messages — message history filtered by threadId
app.get("/api/threads/:id/messages", (req, res) => {
    const threadId = parseInt(req.params.id, 10);
    const limit = Math.min(parseInt(String(req.query.n ?? "50"), 10) || 50, 200);
    const entries = readRecentJsonl<Record<string, unknown>>(
        path.join(BORG_DIR, "message-history.jsonl"),
        500,
    );
    const filtered = entries.filter(e => e.threadId === threadId).slice(-limit);
    res.json(filtered);
});

// GET /api/messages/recent?n=50 — recent messages across all threads
app.get("/api/messages/recent", (req, res) => {
    const n = Math.min(parseInt(String(req.query.n ?? "50"), 10) || 50, 200);
    const entries = readRecentJsonl(path.join(BORG_DIR, "message-history.jsonl"), n);
    res.json(entries);
});

// GET /api/messages/feed — SSE stream of new messages (broadcast pattern)
app.get("/api/messages/feed", (_req, res) => {
    res.writeHead(200, {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        Connection: "keep-alive",
    });
    res.write(":\n\n"); // SSE comment to establish connection

    const historyFile = path.join(BORG_DIR, "message-history.jsonl");
    const tailState: TailState = { offset: 0 };

    // Initialize to current EOF so we only send new messages
    if (fs.existsSync(historyFile)) {
        const stat = fs.statSync(historyFile);
        tailState.offset = stat.size;
    }

    const client: FeedClient = { res, tailState };
    messageFeedClients.add(client);
    startMessageFeed();

    _req.on("close", () => {
        messageFeedClients.delete(client);
        stopMessageFeedIfIdle();
    });
});

// GET /api/routing/feed — SSE stream of routing decisions (broadcast pattern)
app.get("/api/routing/feed", (_req, res) => {
    res.writeHead(200, {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        Connection: "keep-alive",
    });
    res.write(":\n\n");

    const routingFile = path.join(BORG_DIR, "logs/routing.jsonl");
    const tailState: TailState = { offset: 0 };

    if (fs.existsSync(routingFile)) {
        const stat = fs.statSync(routingFile);
        tailState.offset = stat.size;
    }

    const client: FeedClient = { res, tailState };
    routingFeedClients.add(client);
    startRoutingFeed();

    _req.on("close", () => {
        routingFeedClients.delete(client);
        stopRoutingFeedIfIdle();
    });
});

// GET /api/routing/recent?n=50
app.get("/api/routing/recent", (req, res) => {
    const n = Math.min(parseInt(String(req.query.n ?? "50"), 10) || 50, 200);
    const entries = readRecentJsonl(path.join(BORG_DIR, "logs/routing.jsonl"), n);
    res.json(entries);
});

// GET /api/prompts/recent?n=20
app.get("/api/prompts/recent", (req, res) => {
    const n = Math.min(parseInt(String(req.query.n ?? "20"), 10) || 20, 200);
    const entries = readRecentJsonl(path.join(BORG_DIR, "logs/prompts.jsonl"), n);
    res.json(entries);
});

// GET /api/metrics — CPU, RAM, disk, load
app.get("/api/metrics", (_req, res) => {
    const memBytes = parseMeminfo();
    res.json({
        cpu: parseCpuPercent(),
        mem: {
            totalMB: Math.round(memBytes.totalBytes / 1024 / 1024),
            usedMB: Math.round((memBytes.totalBytes - memBytes.availableBytes) / 1024 / 1024),
            availableMB: Math.round(memBytes.availableBytes / 1024 / 1024),
        },
        load: parseLoadAvg(),
        disk: getDiskUsage(BORG_DIR),
        timestamp: Date.now(),
    });
});

// ─── Docker Container Management ───

function parseMemoryLimit(limit: string): number | null {
    const match = limit.match(/^(\d+(?:\.\d+)?)\s*(b|k|kb|m|mb|g|gb)?$/i);
    if (!match) return null;
    const num = parseFloat(match[1]);
    const unit = (match[2] || "b").toLowerCase();
    switch (unit) {
        case "k":
        case "kb":
            return Math.round(num * 1024);
        case "m":
        case "mb":
            return Math.round(num * 1024 * 1024);
        case "g":
        case "gb":
            return Math.round(num * 1024 * 1024 * 1024);
        default:
            return Math.round(num);
    }
}

// ─── SSE Broadcast Infrastructure ───

// Per-client state for JSONL tail feeds (each client tracks its own byte offset)
interface FeedClient {
    res: http.ServerResponse;
    tailState: TailState;
}

// ─── Message Feed (broadcast pattern) ───

const messageFeedClients = new Set<FeedClient>();
let messageFeedInterval: ReturnType<typeof setInterval> | null = null;

function startMessageFeed(): void {
    if (messageFeedInterval) return;
    const historyFile = path.join(BORG_DIR, "message-history.jsonl");
    messageFeedInterval = setInterval(() => {
        if (messageFeedClients.size === 0) return;
        for (const client of messageFeedClients) {
            const content = readNewBytes(historyFile, client.tailState);
            if (content === null) continue;
            const lines = content.split("\n").filter(l => l.trim());
            for (const line of lines) {
                try { JSON.parse(line); } catch { continue; } // skip malformed
                try {
                    client.res.write(`data: ${line}\n\n`);
                } catch {
                    messageFeedClients.delete(client);
                    break;
                }
            }
        }
    }, 2000);
}

function stopMessageFeedIfIdle(): void {
    if (messageFeedClients.size === 0 && messageFeedInterval) {
        clearInterval(messageFeedInterval);
        messageFeedInterval = null;
    }
}

// ─── Routing Feed (broadcast pattern) ───

const routingFeedClients = new Set<FeedClient>();
let routingFeedInterval: ReturnType<typeof setInterval> | null = null;

function startRoutingFeed(): void {
    if (routingFeedInterval) return;
    const routingFile = path.join(BORG_DIR, "logs/routing.jsonl");
    routingFeedInterval = setInterval(() => {
        if (routingFeedClients.size === 0) return;
        for (const client of routingFeedClients) {
            const content = readNewBytes(routingFile, client.tailState);
            if (content === null) continue;
            const lines = content.split("\n").filter(l => l.trim());
            for (const line of lines) {
                try { JSON.parse(line); } catch { continue; } // skip malformed
                try {
                    client.res.write(`data: ${line}\n\n`);
                } catch {
                    routingFeedClients.delete(client);
                    break;
                }
            }
        }
    }, 2000);
}

function stopRoutingFeedIfIdle(): void {
    if (routingFeedClients.size === 0 && routingFeedInterval) {
        clearInterval(routingFeedInterval);
        routingFeedInterval = null;
    }
}

// ─── Log Feed (broadcast pattern, one group per log type) ───

const logFeedClients: Record<string, Set<FeedClient>> = {};
const logFeedIntervals: Record<string, ReturnType<typeof setInterval>> = {};

function getLogFilePath(type: string): string {
    return type === "telegram"
        ? path.join(BORG_DIR, "logs/telegram.log")
        : path.join(BORG_DIR, "logs/queue.log");
}

function startLogFeed(type: string): void {
    if (logFeedIntervals[type]) return;
    if (!logFeedClients[type]) logFeedClients[type] = new Set();
    const logFile = getLogFilePath(type);
    logFeedIntervals[type] = setInterval(() => {
        const clients = logFeedClients[type];
        if (!clients || clients.size === 0) return;
        for (const client of clients) {
            const content = readNewBytes(logFile, client.tailState);
            if (content === null) continue;
            const lines = content.split("\n").filter(l => l.trim());
            for (const line of lines) {
                try {
                    client.res.write(`data: ${JSON.stringify(line)}\n\n`);
                } catch {
                    clients.delete(client);
                    break;
                }
            }
        }
    }, 2000);
}

function stopLogFeedIfIdle(type: string): void {
    const clients = logFeedClients[type];
    if ((!clients || clients.size === 0) && logFeedIntervals[type]) {
        clearInterval(logFeedIntervals[type]);
        delete logFeedIntervals[type];
    }
}

// ─── Container Feed (server-side polling with broadcast) ───

const containerFeedClients = new Set<http.ServerResponse>();
let containerFeedInterval: ReturnType<typeof setInterval> | null = null;
let containerFeedPolling = false;

function startContainerFeed(): void {
    if (containerFeedInterval) return;
    containerFeedInterval = setInterval(async () => {
        if (containerFeedClients.size === 0) return;
        // Skip this tick if the previous poll is still running (overlap guard)
        if (containerFeedPolling) return;
        containerFeedPolling = true;
        try {
            const containers = await getAllContainers(DOCKER_PROXY_URL, COMPOSE_PROJECT);
            const host = parseMeminfo();
            const allocatedTotal = containers
                .filter(c => !c.memory.unlimited)
                .reduce((sum, c) => sum + c.memory.limit, 0);
            const unlimitedCount = containers.filter(c => c.memory.unlimited).length;
            const data = JSON.stringify({
                containers,
                host: {
                    totalMemory: host.totalBytes,
                    availableMemory: host.availableBytes,
                    allocatedTotal,
                    osReserve: OS_RESERVE_BYTES,
                    unlimitedCount,
                },
            });
            for (const client of containerFeedClients) {
                try {
                    client.write(`data: ${data}\n\n`);
                } catch {
                    containerFeedClients.delete(client);
                }
            }
        } catch {
            // Docker API may be unavailable, skip this tick
        } finally {
            containerFeedPolling = false;
        }
    }, 5000);
}

function stopContainerFeedIfIdle(): void {
    if (containerFeedClients.size === 0 && containerFeedInterval) {
        clearInterval(containerFeedInterval);
        containerFeedInterval = null;
    }
}

// GET /api/containers — list all dev containers with memory stats
app.get("/api/containers", async (_req, res) => {
    try {
        const containers = await getAllContainers(DOCKER_PROXY_URL, COMPOSE_PROJECT);
        const host = parseMeminfo();
        const allocatedTotal = containers
            .filter(c => !c.memory.unlimited)
            .reduce((sum, c) => sum + c.memory.limit, 0);
        const unlimitedCount = containers.filter(c => c.memory.unlimited).length;
        res.json({
            containers,
            host: {
                totalMemory: host.totalBytes,
                availableMemory: host.availableBytes,
                allocatedTotal,
                osReserve: OS_RESERVE_BYTES,
                unlimitedCount,
            },
        });
    } catch (err) {
        const msg = toErrorMessage(err);
        res.status(502).json({ error: "Failed to fetch containers", detail: msg });
    }
});

// GET /api/containers/:id/stats — live memory stats for a specific container
app.get("/api/containers/:id/stats", async (req, res) => {
    try {
        const containerId = String(req.params.id);
        if (!isValidContainerId(containerId)) {
            res.status(400).json({ error: "Invalid container ID. Expected 12-64 hex characters." });
            return;
        }
        const stats = await fetchDockerStats(DOCKER_PROXY_URL, containerId);
        const inspect = await fetchDockerJson<DockerContainerInspect>(
            DOCKER_PROXY_URL,
            `/containers/${containerId}/json`,
        );
        const usage = stats.memory_stats?.usage || 0;
        const limit = inspect.HostConfig.Memory || stats.memory_stats?.limit || 0;
        res.json({
            id: containerId,
            name: (inspect.Name || "").replace(/^\//, ""),
            memory: {
                usage,
                limit,
                usagePercent: limit > 0 ? Math.round((usage / limit) * 1000) / 10 : 0,
            },
            pids: stats.pids_stats?.current || 0,
        });
    } catch (err) {
        const msg = toErrorMessage(err);
        res.status(502).json({ error: "Failed to fetch container stats", detail: msg });
    }
});

// POST /api/containers/:id/memory — update memory limit
app.post("/api/containers/:id/memory", async (req, res) => {
    try {
        const containerId = String(req.params.id);
        if (!isValidContainerId(containerId)) {
            res.status(400).json({ error: "Invalid container ID. Expected 12-64 hex characters." });
            return;
        }
        const limitStr = (req.body as { limit?: string })?.limit;
        if (!limitStr || typeof limitStr !== "string") {
            res.status(400).json({ error: "Missing or invalid 'limit' field (e.g. '4g', '2048m')" });
            return;
        }

        const newLimitBytes = parseMemoryLimit(limitStr);
        if (newLimitBytes === null) {
            res.status(400).json({ error: "Invalid memory limit format. Use e.g. '4g', '2048m', '1.5gb'" });
            return;
        }
        const hostMem = parseMeminfo();

        const result = await validateAndUpdateMemory(
            DOCKER_PROXY_URL,
            containerId,
            newLimitBytes,
            hostMem.totalBytes,
            COMPOSE_PROJECT,
        );

        res.json(result);
    } catch (err) {
        const msg = toErrorMessage(err);
        const status = err instanceof ValidationError ? 400 : 502;
        res.status(status).json({ error: msg });
    }
});

// GET /api/host/memory — host total RAM and current usage
app.get("/api/host/memory", (_req, res) => {
    const hostMem = parseMeminfo();
    res.json({
        totalMemory: hostMem.totalBytes,
        availableMemory: hostMem.availableBytes,
        usedMemory: hostMem.totalBytes - hostMem.availableBytes,
        osReserve: OS_RESERVE_BYTES,
        maxAllocatable: hostMem.totalBytes - OS_RESERVE_BYTES,
    });
});

// GET /api/containers/feed — SSE stream of container memory stats
app.get("/api/containers/feed", (_req, res) => {
    res.writeHead(200, {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        Connection: "keep-alive",
    });
    res.write(":\n\n"); // SSE comment to establish connection

    containerFeedClients.add(res);
    startContainerFeed();

    _req.on("close", () => {
        containerFeedClients.delete(res);
        stopContainerFeedIfIdle();
    });
});

// ─── Session Log Helpers ───

function findSessionLogFile(sessionId: string): string | null {
    // Validate sessionId format (UUID) to prevent path traversal
    if (!isValidSessionId(sessionId)) return null;

    const safeId = path.basename(sessionId); // defense in depth
    const logFile = path.join(SESSIONS_DIR, `${safeId}.jsonl`);

    // Verify resolved path stays within SESSIONS_DIR
    const resolvedPath = path.resolve(logFile);
    const resolvedSessionsDir = path.resolve(SESSIONS_DIR);
    if (!resolvedPath.startsWith(resolvedSessionsDir + path.sep)) return null;

    if (fs.existsSync(logFile)) return logFile;
    return null;
}

function tailLines(filePath: string, n: number): string[] {
    const stat = fs.statSync(filePath);
    if (stat.size === 0) return [];

    const TAIL_BYTES = Math.min(128 * 1024, stat.size);
    const fd = fs.openSync(filePath, "r");
    try {
        const buf = Buffer.alloc(TAIL_BYTES);
        fs.readSync(fd, buf, 0, TAIL_BYTES, Math.max(0, stat.size - TAIL_BYTES));
        const content = buf.toString("utf8");
        const lines = content.split("\n").filter(l => l.trim());
        return lines.slice(-n);
    } finally {
        fs.closeSync(fd);
    }
}

// GET /api/threads/:id/session-logs?n=20 — tail of Claude SDK session log
app.get("/api/threads/:id/session-logs", (req, res) => {
    const threadId = req.params.id;
    const n = Math.min(parseInt(String(req.query.n ?? "20"), 10) || 20, 200);

    const threads = readJsonSafe<Record<string, { sessionId?: string; cwd?: string }>>(
        path.join(BORG_DIR, "threads.json"),
        {},
    );

    const threadConfig = threads[threadId];
    if (!threadConfig?.sessionId) {
        res.json({ lines: [], error: "No active session" });
        return;
    }

    const logFile = findSessionLogFile(threadConfig.sessionId);
    if (!logFile) {
        res.json({ lines: [], error: "Log file not found", sessionId: threadConfig.sessionId });
        return;
    }

    const lines = tailLines(logFile, n);
    res.json({ lines, sessionId: threadConfig.sessionId, logFile });
});

// GET /api/session-logs?n=20 — all active threads' session log tails
app.get("/api/session-logs", (req, res) => {
    const n = Math.min(parseInt(String(req.query.n ?? "20"), 10) || 20, 200);

    const threads = readJsonSafe<Record<string, { sessionId?: string; name?: string }>>(
        path.join(BORG_DIR, "threads.json"),
        {},
    );

    const results: Record<string, { name: string; lines: string[]; sessionId: string }> = {};

    for (const [threadId, config] of Object.entries(threads)) {
        if (!config.sessionId) continue;

        const logFile = findSessionLogFile(config.sessionId);
        if (logFile) {
            results[threadId] = {
                name: config.name || `Thread ${threadId}`,
                lines: tailLines(logFile, n),
                sessionId: config.sessionId,
            };
        }
    }

    res.json(results);
});

// GET /api/logs/:type — SSE stream of log files (telegram | queue) (broadcast pattern)
app.get("/api/logs/:type", (req, res) => {
    const type = req.params.type;
    if (type !== "telegram" && type !== "queue") {
        res.status(400).json({ error: "Invalid log type. Use 'telegram' or 'queue'." });
        return;
    }
    const logFile = getLogFilePath(type);

    res.writeHead(200, {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        Connection: "keep-alive",
    });
    res.write(":\n\n");

    const tailState: TailState = { offset: 0 };

    if (fs.existsSync(logFile)) {
        const stat = fs.statSync(logFile);
        // Start from last 4KB to show some initial context
        tailState.offset = Math.max(0, stat.size - 4096);
    }

    const client: FeedClient = { res, tailState };
    if (!logFeedClients[type]) logFeedClients[type] = new Set();
    logFeedClients[type].add(client);
    startLogFeed(type);

    req.on("close", () => {
        logFeedClients[type]?.delete(client);
        stopLogFeedIfIdle(type);
    });
});

// ─── Start Server ───

const server = http.createServer(app);

server.listen(PORT, "0.0.0.0", () => {
    console.log(`Dashboard listening on http://0.0.0.0:${PORT}`);
    console.log(`Monitoring: ${BORG_DIR}`);
});

// Graceful shutdown
process.on("SIGTERM", () => {
    console.log("Dashboard shutting down...");
    server.close(() => process.exit(0));
});
process.on("SIGINT", () => {
    console.log("Dashboard shutting down...");
    server.close(() => process.exit(0));
});
